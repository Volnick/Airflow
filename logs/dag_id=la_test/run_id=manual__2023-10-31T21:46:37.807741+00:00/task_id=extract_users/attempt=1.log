[2023-10-31T22:48:09.055+0100] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: la_test.extract_users manual__2023-10-31T21:46:37.807741+00:00 [queued]>
[2023-10-31T22:48:09.058+0100] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: la_test.extract_users manual__2023-10-31T21:46:37.807741+00:00 [queued]>
[2023-10-31T22:48:09.058+0100] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2023-10-31T22:48:09.063+0100] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): extract_users> on 2023-10-31 21:46:37.807741+00:00
[2023-10-31T22:48:09.066+0100] {standard_task_runner.py:57} INFO - Started process 67053 to run task
[2023-10-31T22:48:09.069+0100] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'la_test', 'extract_users', 'manual__2023-10-31T21:46:37.807741+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/test_aj.py', '--cfg-path', '/var/folders/4w/73_t653s0rz1z847_g217g2h0000gn/T/tmp5r8qk61c']
[2023-10-31T22:48:09.069+0100] {standard_task_runner.py:85} INFO - Job 68: Subtask extract_users
[2023-10-31T22:48:09.089+0100] {task_command.py:416} INFO - Running <TaskInstance: la_test.extract_users manual__2023-10-31T21:46:37.807741+00:00 [running]> on host mbp21-14
[2023-10-31T22:48:09.117+0100] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='la_test' AIRFLOW_CTX_TASK_ID='extract_users' AIRFLOW_CTX_EXECUTION_DATE='2023-10-31T21:46:37.807741+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-10-31T21:46:37.807741+00:00'
[2023-10-31T22:48:13.104+0100] {local_task_job_runner.py:121} CRITICAL - 
******************************************* Received SIGSEGV *******************************************
SIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to
an attempt by a program/library to write or read outside its allocated memory.

In Python environment usually this signal refers to libraries which use low level C API.
Make sure that you use right libraries/Docker Images
for your architecture (Intel/ARM) and/or Operational System (Linux/macOS).

Suggested way to debug
======================
  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.
  - Start airflow services.
  - Restart failed airflow task.
  - Check 'scheduler' and 'worker' services logs for additional traceback
    which might contain information about module/library where actual error happen.

Known Issues
============

Note: Only Linux-based distros supported as "Production" execution environment for Airflow.

macOS
-----
 1. Due to limitations in Apple's libraries not every process might 'fork' safe.
    One of the general error is unable to query the macOS system configuration for network proxies.
    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.
    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958
********************************************************************************************************
[2023-10-31T22:48:13.106+0100] {local_task_job_runner.py:121} CRITICAL - 
******************************************* Received SIGSEGV *******************************************
SIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to
an attempt by a program/library to write or read outside its allocated memory.

In Python environment usually this signal refers to libraries which use low level C API.
Make sure that you use right libraries/Docker Images
for your architecture (Intel/ARM) and/or Operational System (Linux/macOS).

Suggested way to debug
======================
  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.
  - Start airflow services.
  - Restart failed airflow task.
  - Check 'scheduler' and 'worker' services logs for additional traceback
    which might contain information about module/library where actual error happen.

Known Issues
============

Note: Only Linux-based distros supported as "Production" execution environment for Airflow.

macOS
-----
 1. Due to limitations in Apple's libraries not every process might 'fork' safe.
    One of the general error is unable to query the macOS system configuration for network proxies.
    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.
    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958
********************************************************************************************************
[2023-10-31T22:48:13.108+0100] {local_task_job_runner.py:228} INFO - Task exited with return code 139
[2023-10-31T22:50:39.991+0100] {local_task_job_runner.py:294} WARNING - State of this instance has been externally set to success. Terminating instance.
[2023-10-31T22:50:39.996+0100] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 67053. PIDs of all processes in the group: [67053]
[2023-10-31T22:50:39.996+0100] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 67053
[2023-10-31T22:51:40.037+0100] {process_utils.py:149} WARNING - process psutil.Process(pid=67053, name='python3.9', status='running', started='22:48:09') did not respond to SIGTERM. Trying SIGKILL
[2023-10-31T22:51:40.039+0100] {process_utils.py:86} INFO - Sending the signal Signals.SIGKILL to group 67053
[2023-10-31T22:51:40.071+0100] {process_utils.py:79} INFO - Process psutil.Process(pid=67053, name='python3.9', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='22:48:09') (67053) terminated with exit code Negsignal.SIGKILL
[2023-10-31T22:51:40.071+0100] {standard_task_runner.py:172} ERROR - Job 68 was killed before it finished (likely due to running out of memory)
