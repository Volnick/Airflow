[2023-10-31T22:51:41.690+0100] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: la_test.extract_channel_messages manual__2023-10-31T21:46:37.807741+00:00 [queued]>
[2023-10-31T22:51:41.693+0100] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: la_test.extract_channel_messages manual__2023-10-31T21:46:37.807741+00:00 [queued]>
[2023-10-31T22:51:41.693+0100] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2023-10-31T22:51:41.698+0100] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): extract_channel_messages> on 2023-10-31 21:46:37.807741+00:00
[2023-10-31T22:51:41.701+0100] {standard_task_runner.py:57} INFO - Started process 67327 to run task
[2023-10-31T22:51:41.704+0100] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'la_test', 'extract_channel_messages', 'manual__2023-10-31T21:46:37.807741+00:00', '--job-id', '69', '--raw', '--subdir', 'DAGS_FOLDER/test_aj.py', '--cfg-path', '/var/folders/4w/73_t653s0rz1z847_g217g2h0000gn/T/tmpaeb6_1t2']
[2023-10-31T22:51:41.705+0100] {standard_task_runner.py:85} INFO - Job 69: Subtask extract_channel_messages
[2023-10-31T22:51:41.722+0100] {task_command.py:416} INFO - Running <TaskInstance: la_test.extract_channel_messages manual__2023-10-31T21:46:37.807741+00:00 [running]> on host mbp21-14
[2023-10-31T22:51:41.749+0100] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='la_test' AIRFLOW_CTX_TASK_ID='extract_channel_messages' AIRFLOW_CTX_EXECUTION_DATE='2023-10-31T21:46:37.807741+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-10-31T21:46:37.807741+00:00'
[2023-10-31T22:51:41.851+0100] {secrets_masker.py:280} WARNING - Unable to redact '\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable \'PYTHONFAULTHANDLER\' to \'true\'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check \'scheduler\' and \'worker\' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as "Production" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple\'s libraries not every process might \'fork\' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable \'no_proxy\' to \'*\'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************', please report this via <https://github.com/apache/airflow/issues>. Error was: RecursionError: maximum recursion depth exceeded
[2023-10-31T22:51:42.056+0100] {local_task_job_runner.py:121} CRITICAL - 
******************************************* Received SIGSEGV *******************************************
SIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to
an attempt by a program/library to write or read outside its allocated memory.

In Python environment usually this signal refers to libraries which use low level C API.
Make sure that you use right libraries/Docker Images
for your architecture (Intel/ARM) and/or Operational System (Linux/macOS).

Suggested way to debug
======================
  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.
  - Start airflow services.
  - Restart failed airflow task.
  - Check 'scheduler' and 'worker' services logs for additional traceback
    which might contain information about module/library where actual error happen.

Known Issues
============

Note: Only Linux-based distros supported as "Production" execution environment for Airflow.

macOS
-----
 1. Due to limitations in Apple's libraries not every process might 'fork' safe.
    One of the general error is unable to query the macOS system configuration for network proxies.
    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.
    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958
********************************************************************************************************
[2023-10-31T22:51:42.057+0100] {local_task_job_runner.py:228} INFO - Task exited with return code 139
[2023-10-31T22:51:43.223+0100] {local_task_job_runner.py:121} CRITICAL - 
******************************************* Received SIGSEGV *******************************************
SIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to
an attempt by a program/library to write or read outside its allocated memory.

In Python environment usually this signal refers to libraries which use low level C API.
Make sure that you use right libraries/Docker Images
for your architecture (Intel/ARM) and/or Operational System (Linux/macOS).

Suggested way to debug
======================
  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.
  - Start airflow services.
  - Restart failed airflow task.
  - Check 'scheduler' and 'worker' services logs for additional traceback
    which might contain information about module/library where actual error happen.

Known Issues
============

Note: Only Linux-based distros supported as "Production" execution environment for Airflow.

macOS
-----
 1. Due to limitations in Apple's libraries not every process might 'fork' safe.
    One of the general error is unable to query the macOS system configuration for network proxies.
    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.
    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958
********************************************************************************************************
[2023-10-31T22:51:43.224+0100] {local_task_job_runner.py:228} INFO - Task exited with return code 139
[2023-10-31T22:51:43.637+0100] {secrets_masker.py:280} WARNING - Unable to redact '\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable \'PYTHONFAULTHANDLER\' to \'true\'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check \'scheduler\' and \'worker\' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as "Production" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple\'s libraries not every process might \'fork\' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable \'no_proxy\' to \'*\'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************', please report this via <https://github.com/apache/airflow/issues>. Error was: RecursionError: maximum recursion depth exceeded
[2023-10-31T22:51:43.637+0100] {local_task_job_runner.py:121} CRITICAL - 
******************************************* Received SIGSEGV *******************************************
SIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to
an attempt by a program/library to write or read outside its allocated memory.

In Python environment usually this signal refers to libraries which use low level C API.
Make sure that you use right libraries/Docker Images
for your architecture (Intel/ARM) and/or Operational System (Linux/macOS).

Suggested way to debug
======================
  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.
  - Start airflow services.
  - Restart failed airflow task.
  - Check 'scheduler' and 'worker' services logs for additional traceback
    which might contain information about module/library where actual error happen.

Known Issues
============

Note: Only Linux-based distros supported as "Production" execution environment for Airflow.

macOS
-----
 1. Due to limitations in Apple's libraries not every process might 'fork' safe.
    One of the general error is unable to query the macOS system configuration for network proxies.
    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.
    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958
********************************************************************************************************
[2023-10-31T22:51:44.439+0100] {local_task_job_runner.py:121} CRITICAL - 
******************************************* Received SIGSEGV *******************************************
SIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to
an attempt by a program/library to write or read outside its allocated memory.

In Python environment usually this signal refers to libraries which use low level C API.
Make sure that you use right libraries/Docker Images
for your architecture (Intel/ARM) and/or Operational System (Linux/macOS).

Suggested way to debug
======================
  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.
  - Start airflow services.
  - Restart failed airflow task.
  - Check 'scheduler' and 'worker' services logs for additional traceback
    which might contain information about module/library where actual error happen.

Known Issues
============

Note: Only Linux-based distros supported as "Production" execution environment for Airflow.

macOS
-----
 1. Due to limitations in Apple's libraries not every process might 'fork' safe.
    One of the general error is unable to query the macOS system configuration for network proxies.
    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.
    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958
********************************************************************************************************
[2023-10-31T22:51:44.741+0100] {secrets_masker.py:280} WARNING - Unable to redact '\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable \'PYTHONFAULTHANDLER\' to \'true\'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check \'scheduler\' and \'worker\' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as "Production" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple\'s libraries not every process might \'fork\' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable \'no_proxy\' to \'*\'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************', please report this via <https://github.com/apache/airflow/issues>. Error was: RecursionError: maximum recursion depth exceeded while calling a Python object
[2023-10-31T22:52:21.887+0100] {local_task_job_runner.py:294} WARNING - State of this instance has been externally set to success. Terminating instance.
[2023-10-31T22:52:21.893+0100] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 67327. PIDs of all processes in the group: [67327]
[2023-10-31T22:52:21.893+0100] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 67327
[2023-10-31T22:53:21.938+0100] {process_utils.py:149} WARNING - process psutil.Process(pid=67327, name='python3.9', status='running', started='22:51:41') did not respond to SIGTERM. Trying SIGKILL
[2023-10-31T22:53:21.941+0100] {process_utils.py:86} INFO - Sending the signal Signals.SIGKILL to group 67327
[2023-10-31T22:53:21.958+0100] {process_utils.py:79} INFO - Process psutil.Process(pid=67327, name='python3.9', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='22:51:41') (67327) terminated with exit code Negsignal.SIGKILL
[2023-10-31T22:53:21.958+0100] {standard_task_runner.py:172} ERROR - Job 69 was killed before it finished (likely due to running out of memory)
